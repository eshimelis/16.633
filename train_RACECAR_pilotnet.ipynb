{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "train_RACECAR_pilotnet.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eshimelis/16.633/blob/master/train_RACECAR_pilotnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBbGHfcgb7L6",
        "colab_type": "text"
      },
      "source": [
        "# PilotNet Imitation Learning Lab\n",
        "## NEET Fall 2019\n",
        "\n",
        "Written by Mark Mazumder, edited by Eyassu Shimelis for Google Colab Support\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UxnB7jEcdeH",
        "colab_type": "text"
      },
      "source": [
        "## Setup the Colab Runtime\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YLqgdQ4ILbe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-latest-Linux-x86_64.sh\n",
        "!bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0CapgBCcmE3",
        "colab_type": "text"
      },
      "source": [
        "Veirfy that conda is successfully installed:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QwTwqSEJeJI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!which conda"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLymV4SOHjLX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd /content\n",
        "!git clone https://github.com/mmaz/imitation_learning_lab\n",
        "\n",
        "# https://stackoverflow.com/questions/49202649/how-to-build-libraries-via-conda-on-colab-research\n",
        "!conda env create --prefix /usr/local/lib/python3.7/site-packages -f imitation_learning_lab/environment-gpu.yml\n",
        "!conda init bash\n",
        "\n",
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.7/site-packages')\n",
        "\n",
        "%cd imitation_learning_lab/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrDlXaTRD_yr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "# the below commands allow you to edit and reload pilotnet.py without \n",
        "# restarting the notebook kernel - use with caution!\n",
        "\n",
        "# https://ipython.org/ipython-doc/3/config/extensions/autoreload.html\n",
        "%load_ext autoreload\n",
        "%autoreload 1\n",
        "%aimport pilotnet\n",
        "\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MLFSwDeD_yu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Lambda, Conv2D, MaxPooling2D, Dropout, Dense, Flatten, Input, Activation, add\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import os\n",
        "import datetime\n",
        "import glob\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# some parameters and image preprocessing functions for pilotnet:\n",
        "import pilotnet as p"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qudDAEXD_yx",
        "colab_type": "text"
      },
      "source": [
        "To copy data from the car, you can use the below `scp` command. First **replace `RACECAR_IP`** with the address to your car, and **replace `**_DATE**`** with the current date (using the format specified in `record_RACECAR.py`. This will copy the folder containing training images and the steering angle CSV (from `record_RACECAR.py`) to the current directory, where you will train your model.\n",
        "\n",
        "```\n",
        "scp -r racecar@RACECAR_IP:~/imitation_learning_lab/data_DATE ./data_and_models/collects/\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNAthemJdkYu",
        "colab_type": "text"
      },
      "source": [
        "## Accessing Your Driving Data\n",
        "\n",
        "Google Colab allows you to connect external files and folders in a number of ways. For now, we'll be using Google Drive. Place your training folder in an easy-to-find location somewhere on your personal Google Drive.\n",
        "\n",
        "The block of code below is to allow Google Colab to mount your Google Drive directory. When you run it, you will be prompted to follow a link and allow access by copying and pasting an access token back into this notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZVNe-4DMoNy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeXKvR8tnypm",
        "colab_type": "text"
      },
      "source": [
        "You can treat treat the newly mounted file just like any other directory! Make sure to update the filepath below with the one you used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hclSdb8CD_yz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CSV and jpgs from record_RACECAR.py\n",
        "driving_data = [ \"/content/drive/My Drive/Colab Notebooks/training/data_10_28_16_14/data_10_28_16_14.csv\"\n",
        "                # example filepath for a Google Drive file: \"/content/drive/My Drive/.../<FILE>.csv\"\n",
        "                # additional cvs can be provided here\n",
        "               ]\n",
        "\n",
        "for f in driving_data:\n",
        "    parent_dir = os.path.dirname(f) + os.path.sep\n",
        "    print(parent_dir)\n",
        "    print(os.listdir(parent_dir))\n",
        "    print(len(os.listdir(parent_dir)), \" files found\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qi58QcLjD_y2",
        "colab_type": "text"
      },
      "source": [
        "This notebook will train an implementation of Nvidia's PilotNet using TensorFlow/Keras. As an exercise you should modify some or all of the following and compare against the baseline implementation here.\n",
        "\n",
        "* Drop out probability\n",
        "* Number of epochs  \n",
        "* Samples per epoch  \n",
        "* Batch size         \n",
        "* Learning rate\n",
        "* Model layers, outputs: e.g., add regularization, or speed prediction\n",
        "* Image size (cropped or scaled)\n",
        "* Image augmentation\n",
        "\n",
        "\n",
        "Some comparison metrics:\n",
        "\n",
        "* Can you drive faster than the baseline?\n",
        "* Do you require less data to train? More?\n",
        "* Model generalization:\n",
        "    * Can your model be used on a different car? \n",
        "    * Can you slightly change the angle of the front camera at inference time?\n",
        "    * Does the presence of people or lighting variations affect your model's performance?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iD620tlRD_y3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imgs   = []\n",
        "ngls   = []\n",
        "speeds = []\n",
        "lines  = 0\n",
        "\n",
        "for f in driving_data:\n",
        "    parent_dir = os.path.dirname(f) + os.path.sep\n",
        "    with open(f) as fh:\n",
        "        for line in fh:\n",
        "            lines = lines + 1\n",
        "            l = line.split(',')\n",
        "\n",
        "            speed = l[2]\n",
        "            speed = float(speed)\n",
        "\n",
        "            # filter out data when the car is stopped\n",
        "            #if np.isclose(speed, 0.):\n",
        "            if speed < 0.2:\n",
        "                continue\n",
        "\n",
        "            speeds.append(speed)\n",
        "\n",
        "            img = l[0]\n",
        "            imgs.append(parent_dir + img)\n",
        "\n",
        "            ngl = l[1]\n",
        "            ngl = float(ngl)\n",
        "            ngls.append(ngl)\n",
        "print(\"total data\", lines)\n",
        "print(\"filtered data\", len(imgs), len(ngls), len(speeds))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMzmATxVD_y6",
        "colab_type": "text"
      },
      "source": [
        "These histograms of steering angles and speeds can be useful for sanity checking and considering what you should set `OFFSET_STEERING_ANGLE` to in `pilotnet.py` (which defines the magnitude of the pseudo-\"corrective\" steering angles applied to images taken from the left/right cameras during training below)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UCGUZIgD_y7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax = plt.subplots(ncols=2)\n",
        "ax[0].hist(ngls, bins=50);\n",
        "ax[1].hist(speeds, bins=50);\n",
        "ax[0].set_title(\"steering angles\")\n",
        "ax[1].set_title(\"speeds\")\n",
        "fig.set_size_inches(8,5);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgcvDYGSD_zH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random_id = np.random.randint(0, len(imgs)-1)\n",
        "\n",
        "img = cv.imread(imgs[random_id], cv.IMREAD_COLOR)\n",
        "\n",
        "print(\"angle: {:02.3f}\".format(ngls[random_id]))\n",
        "print(\"image size:\", img.shape)\n",
        "rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
        "fig, ax = plt.subplots()\n",
        "ax.imshow(rgb)\n",
        "fig.set_size_inches(15,5);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XDIb55jD_zP",
        "colab_type": "text"
      },
      "source": [
        "## Image Augmentation\n",
        "\n",
        "Here are some examples of image augmentation. One simply increases the brightness (\"value\" channel in the HSV colorspace), another perturbs the gamma value of the input image, and the third adds a random shadow. Try other augmentation techniques to increase the model's robustness. \n",
        "\n",
        "Note that it can take some experimentation to determine which augmentations help - some augmentation strategies might hurt performance. For instance, would it make sense to flip images horizontally or vertically?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NQHwULPD_zR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def increase_brightness(img):\n",
        "    # perceptually a bit more uniform than perturb_gamma\n",
        "    value = np.random.randint(20,60)\n",
        "    hsv = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
        "    h, s, v = cv.split(hsv)\n",
        "\n",
        "    lim = 255 - value\n",
        "    v[v > lim] = 255\n",
        "    v[v <= lim] += value\n",
        "\n",
        "    final_hsv = cv.merge((h, s, v))\n",
        "    img = cv.cvtColor(final_hsv, cv.COLOR_HSV2BGR)\n",
        "    return img\n",
        "\n",
        "def make_random_gamma():\n",
        "    random_gamma = np.random.normal(1, 0.3)\n",
        "    random_gamma = np.clip(random_gamma, 0.5, 2)\n",
        "    return random_gamma\n",
        "\n",
        "def perturb_gamma(img): # https://stackoverflow.com/a/51174313\n",
        "    gamma = make_random_gamma()\n",
        "    invGamma = 1.0 / gamma\n",
        "    table = np.array([\n",
        "        ((i / 255.0) ** invGamma) * 255\n",
        "        for i in np.arange(0, 256)])\n",
        "    return cv.LUT(img, table.astype(np.uint8))\n",
        "\n",
        "def random_shadow(image):\n",
        "    # source: https://github.com/naokishibuya/car-behavioral-cloning/\n",
        "    #         blob/edf20618fddb975c953f06b0549cba8716e27999/utils.py#L84\n",
        "    # (x1, y1) and (x2, y2) forms a line\n",
        "    # xm, ym gives all the locations of the image\n",
        "    x1, y1 = IMAGE_WIDTH * np.random.rand(), 0\n",
        "    x2, y2 = IMAGE_WIDTH * np.random.rand(), IMAGE_HEIGHT\n",
        "    xm, ym = np.mgrid[0:IMAGE_HEIGHT, 0:IMAGE_WIDTH]\n",
        "\n",
        "    # mathematically speaking, we want to set 1 below the line and zero otherwise\n",
        "    # Our coordinate system is `upside down`.  So, the above the line: \n",
        "    # (ym-y1)/(xm-x1) > (y2-y1)/(x2-x1)\n",
        "    # as x2 == x1 causes zero-division problem, we'll write it in the below form:\n",
        "    # (ym-y1)*(x2-x1) - (y2-y1)*(xm-x1) > 0\n",
        "    mask = np.zeros_like(image[:, :, 1])\n",
        "    mask[(ym - y1) * (x2 - x1) - (y2 - y1) * (xm - x1) > 0] = 1\n",
        "\n",
        "    # choose which side should have shadow and adjust saturation\n",
        "    cond = mask == np.random.randint(2)\n",
        "    s_ratio = np.random.uniform(low=0.7, high=0.9)\n",
        "\n",
        "    # adjust Saturation in HLS(Hue, Light, Saturation)\n",
        "    hls = cv.cvtColor(image, cv.COLOR_BGR2HLS)\n",
        "    hls[:, :, 1][cond] = hls[:, :, 1][cond] * s_ratio\n",
        "    return cv.cvtColor(hls, cv.COLOR_HLS2BGR)\n",
        "\n",
        "# visualize the distribution of random gamma perturbations\n",
        "rg = [make_random_gamma() for i in range(10000)]\n",
        "plt.hist(rg, bins=50);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ejJCYOVD_zW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# visualize the effects of augmentation\n",
        "q = np.copy(rgb)\n",
        "qbgr = cv.cvtColor(q, cv.COLOR_RGB2BGR)\n",
        "if np.random.random() < 0.5:\n",
        "    print(\"increasing brighness\")\n",
        "    qbgr = increase_brightness(qbgr)\n",
        "else:\n",
        "    print(\"random gamma\")\n",
        "    qbgr = perturb_gamma(qbgr)\n",
        "q = cv.cvtColor(qbgr, cv.COLOR_BGR2RGB)\n",
        "plt.imshow(q);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCklOjXRD_za",
        "colab_type": "text"
      },
      "source": [
        "Split the data into training and validation subsets. Optionally randomize order and/or use a fixed seed:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqfJVsknD_zb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VAL_SIZE_FRACTION = 0.15\n",
        "SEED = 56709 #awoo\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    imgs, \n",
        "    ngls, \n",
        "    test_size=VAL_SIZE_FRACTION, \n",
        "    shuffle=False\n",
        ")\n",
        "#,random_state=SEED)\n",
        "\n",
        "print(len(X_train), len(X_valid))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ya8UIGVlD_zf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(dropout_rate=0.5):\n",
        "    model = Sequential()\n",
        "    model.add(Lambda(lambda x: x/127.5-1.0, input_shape=p.INPUT_SHAPE)) #normalize the data\n",
        "    model.add(Conv2D(24, (5,5), strides=(2, 2), activation='elu'))\n",
        "    model.add(Conv2D(36, (5,5), strides=(2, 2), activation='elu'))\n",
        "    model.add(Conv2D(48, (5,5), strides=(2, 2), activation='elu'))\n",
        "    model.add(Conv2D(64, (3,3), activation='elu'))\n",
        "    model.add(Conv2D(64, (3,3), activation='elu'))\n",
        "    model.add(Dropout(dropout_rate)) \n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(100, activation='elu'))\n",
        "    model.add(Dense(50, activation='elu'))\n",
        "    model.add(Dense(10, activation='elu'))\n",
        "    model.add(Dense(1))\n",
        "    model.summary() # prints out the model description\n",
        "    return model\n",
        "\n",
        "model = build_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDQO7WRmD_zj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODEL_NAME = \"beaverworks_loop_{}_\".format(datetime.datetime.now().strftime(\"%m_%d_%H_%M\")) \n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer=Adam(lr=1.0e-4))\n",
        "\n",
        "checkpoint = ModelCheckpoint(MODEL_NAME + '{epoch:03d}.h5',\n",
        "                             monitor='val_loss',\n",
        "                             verbose=0,\n",
        "                             save_best_only=False,\n",
        "                             mode='auto')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPGFk4CUD_zl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def augment(img):\n",
        "    ################################\n",
        "    ## TODO\n",
        "    ## add more augmentations here\n",
        "    #################################\n",
        "\n",
        "    augment = np.random.rand()\n",
        "    # augment half the time\n",
        "    if augment < 0.5:\n",
        "        do_gamma = np.random.rand()\n",
        "        if do_gamma < 0.5:\n",
        "            img = perturb_gamma(img)\n",
        "        else:\n",
        "            img = increase_brightness(img)\n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syp5UZGzD_zp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_generator(image_paths, steering_angles, batch_size, is_training):\n",
        "    \"\"\"\n",
        "    Generate training image give image paths and associated steering angles\n",
        "    \"\"\"\n",
        "    images = np.empty([batch_size, p.IMAGE_HEIGHT, p.IMAGE_WIDTH, p.IMAGE_CHANNELS])\n",
        "    steers = np.empty(batch_size)\n",
        "    while True:\n",
        "        i = 0\n",
        "        for index in np.random.permutation(len(image_paths)):\n",
        "            \n",
        "            image = cv.imread(image_paths[index])\n",
        "            \n",
        "            image = p.preprocess(image)\n",
        "            \n",
        "            groundtruth_steering_angle = steering_angles[index]\n",
        "            \n",
        "            if is_training:\n",
        "                dice = np.random.rand()\n",
        "                images[i] = augment(image)\n",
        "                steers[i] = groundtruth_steering_angle\n",
        "            else: # this only validates with center images and no augmentation\n",
        "                  # will it help to add left/right views and augmentation to your validation set?\n",
        "                  # consider the pros and cons and also try experimenting\n",
        "                images[i] = image\n",
        "                steers[i] = groundtruth_steering_angle\n",
        "            \n",
        "            i += 1\n",
        "            if i == batch_size:\n",
        "                break\n",
        "        yield images, steers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_YTPQlGD_z0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax = plt.subplots(ncols=2)\n",
        "ax[0].hist(y_train, bins=50);\n",
        "ax[0].set_title(\"training steering angles\")\n",
        "ax[1].hist(y_valid, bins=50);\n",
        "ax[1].set_title(\"validation steering angles\")\n",
        "fig.set_size_inches(8,5);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okWRnd9HD_z7",
        "colab_type": "text"
      },
      "source": [
        "# Training\n",
        "\n",
        "Note that comparing training and validation loss is not a perfect measurement of how your RACECAR will perform in Stata basement. Solely using mean squared error on steering angles is perhaps a crude accuracy metric on this task. Also note that if you are not augmenting your validation data (and if your augmentations are not characteristic of the validation data), then the training and validation losses may be tough to compare.\n",
        "\n",
        "Can you develop some more robust testing metrics for your model's performance?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "EKBtO-cWD_z8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE=20\n",
        "# print(len(X_valid)//20)\n",
        "model.fit_generator(generator=batch_generator(X_train, y_train, batch_size=BATCH_SIZE, is_training=True),\n",
        "                    steps_per_epoch=4000,\n",
        "                    epochs=10,\n",
        "                    validation_data=batch_generator(X_valid, y_valid, batch_size=BATCH_SIZE, is_training=False),\n",
        "                    validation_steps=max(len(X_valid) // BATCH_SIZE, 1),          \n",
        "                    callbacks=[checkpoint],\n",
        "                    verbose=1,\n",
        "                    use_multiprocessing=True);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mNm2PSyicRO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!conda activate imitation_learning"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ModbtXOdozGD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}